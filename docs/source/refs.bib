@article{Arnold2009,
abstract = {The type III secretion system (TTSS) is a key mechanism for host cell interaction used by a variety of bacterial pathogens and symbionts of plants and animals including humans. The TTSS represents a molecular syringe with which the bacteria deliver effector proteins directly into the host cell cytosol. Despite the importance of the TTSS for bacterial pathogenesis, recognition and targeting of type III secreted proteins has up until now been poorly understood. Several hypotheses are discussed, including an mRNA-based signal, a chaperon-mediated process, or an N-terminal signal peptide. In this study, we systematically analyzed the amino acid composition and secondary structure of N-termini of 100 experimentally verified effector proteins. Based on this, we developed a machine-learning approach for the prediction of TTSS effector proteins, taking into account N-terminal sequence features such as frequencies of amino acids, short peptides, or residues with certain physico-chemical properties. The resulting computational model revealed a strong type III secretion signal in the Nterminus that can be used to detect effectors with sensitivity of ,71% and selectivity of ,85%. This signal seems to be taxonomically universal and conserved among animal pathogens and plant symbionts, since we could successfully detect effector proteins if the respective group was excluded from training. The application of our prediction approach to 739 complete bacterial and archaeal genome sequences resulted in the identification of between 0% and 12% putative TTSS effector proteins. Comparison of effector proteins with orthologs that are not secreted by the TTSS showed no clear pattern of signal acquisition by fusion, suggesting convergent evolutionary processes shaping the type III secretion signal. The newly developed program EffectiveT3 (http://www.chlamydiaedb.org) is the first universal in silico prediction program for the identification of novel TTSS effectors. Our findings will facilitate further studies on and improve our understanding of type III secretion and its role in pathogen-host interactions. {\textcopyright} 2009 Arnold.},
author = {Arnold, Roland and Brandmaier, Stefan and Kleine, Frederick and Tischler, Patrick and Heinz, Eva and Behrens, Sebastian and Niinikoski, Antti and Mewes, Hans-Werner and Horn, Matthias and Rattei, Thomas},
doi = {10.1371/journal.ppat.1000376},
editor = {Stebbins, C. Erec},
issn = {1553-7374},
journal = {PLoS Pathogens},
month = {Apr},
number = {4},
pages = {e1000376},
pmid = {19390696},
title = {{Sequence-Based Prediction of Type III Secreted Proteins}},
volume = {5},
year = {2009}
}

@article{Yamada2014,
abstract = {Motivation: Although many amino acid substitution matrices have been developed, it has not been well understood which is the best for similarity searches, especially for remote homology detection. Therefore, we collected information related to existing matrices, condensed it and derived a novel matrix that can detect more remote homology than ever.Results: Using principal component analysis with existing matrices and benchmarks, we developed a novel matrix, which we designate as MIQS. The detection performance of MIQS is validated and compared with that of existing general purpose matrices using SSEARCH with optimized gap penalties for each matrix. Results show that MIQS is able to detect more remote homology than the existing matrices on an independent dataset. In addition, the performance of our developed matrix was superior to that of CS-BLAST, which was a novel similarity search method with no amino acid matrix. We also evaluated the alignment quality of matrices and methods, which revealed that MIQS shows higher alignment sensitivity than that with the existing matrix series and CS-BLAST. Fundamentally, these results are expected to constitute good proof of the availability and/or importance of amino acid matrices in sequence analysis. Moreover, with our developed matrix, sophisticated similarity search methods such as sequence-profile and profile-profile comparison methods can be improved further. {\textcopyright} 2013 The Author 2013.},
author = {Yamada, Kazunori and Tomii, Kentaro},
doi = {10.1093/bioinformatics/btt694},
issn = {1460-2059},
journal = {Bioinformatics},
month = {Feb},
number = {3},
pages = {317--325},
pmid = {24281694},
title = {{Revisiting amino acid substitution matrices for identifying distantly related proteins}},
volume = {30},
year = {2014}
}

@article{McDermott2019,
abstract = {{\ldots} SIEVE-Ub is available for download at https://github.com/biodataganache/SIEVE-Ub[p] PeerJ Preprints | https://doi.org/ 10.7287 / peerj . preprints . 27292v1 | CC0 Open Access | rec: 20 Oct 2018, publ: 20 Oct 2018 Page 2. 1 2 Prediction of Bacterial E3 Ubiquitin Ligase Effectors {\ldots}},
author = {McDermott, Jason E. and Cort, John R. and Nakayasu, Ernesto S. and Pruneda, Jonathan N. and Overall, Christopher and Adkins, Joshua N.},
doi = {10.7717/peerj.7055},
issn = {2167-8359},
journal = {PeerJ},
month = {Jun},
pages = {e7055},
title = {{Prediction of bacterial E3 ubiquitin ligase effectors using reduced amino acid peptide fingerprinting}},
volume = {7},
year = {2019}
}

@article{Ramesh2022,
abstract = {Contrastive models like CLIP have been shown to learn robust representations of images that capture both semantics and style. To leverage these representations for image generation, we propose a two-stage model: a prior that generates a CLIP image embedding given a text caption, and a decoder that generates an image conditioned on the image embedding. We show that explicitly generating image representations improves image diversity with minimal loss in photorealism and caption similarity. Our decoders conditioned on image representations can also produce variations of an image that preserve both its semantics and style, while varying the non-essential details absent from the image representation. Moreover, the joint embedding space of CLIP enables language-guided image manipulations in a zero-shot fashion. We use diffusion models for the decoder and experiment with both autoregressive and diffusion models for the prior, finding that the latter are computationally more efficient and produce higher-quality samples.},
archivePrefix = {arXiv},
arxivId = {2204.06125},
journal = {},
author = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
eprint = {2204.06125},
month = {Apr},
number = {Figure 3},
title = {{Hierarchical Text-Conditional Image Generation with CLIP Latents}},
year = {2022}
}

@online{GmailSpam,
  author = {Neil Kumaran},
  title = {Spam does not bring us joy --- ridding Gmail of 100 million more spam messages with TensorFlow},
  year = 2019,
  url = {https://cloud.google.com/blog/products/g-suite/ridding-gmail-of-100-million-more-spam-messages-with-tensorflow},
  urldate = {2022-09-20}
}

@article{NLLBTeam2022,
abstract = {Driven by the goal of eradicating language barriers on a global scale, machine translation has solidified itself as a key focus of artificial intelligence research today. However, such efforts have coalesced around a small subset of languages, leaving behind the vast majority of mostly low-resource languages. What does it take to break the 200 language barrier while ensuring safe, high quality results, all while keeping ethical considerations in mind? In No Language Left Behind, we took on this challenge by first contextualizing the need for low-resource language translation support through exploratory interviews with native speakers. Then, we created datasets and models aimed at narrowing the performance gap between low and high-resource languages. More specifically, we developed a conditional compute model based on Sparsely Gated Mixture of Experts that is trained on data obtained with novel and effective data mining techniques tailored for low-resource languages. We propose multiple architectural and training improvements to counteract overfitting while training on thousands of tasks. Critically, we evaluated the performance of over 40,000 different translation directions using a human-translated benchmark, Flores-200, and combined human evaluation with a novel toxicity benchmark covering all languages in Flores-200 to assess translation safety. Our model achieves an improvement of 44% BLEU relative to the previous state-of-the-art, laying important groundwork towards realizing a universal translation system. Finally, we open source all contributions described in this work, accessible at https://github.com/facebookresearch/fairseq/tree/nllb.},
archivePrefix = {arXiv},
arxivId = {2207.04672},
journal = {},
author = {{NLLB Team} and Costa-juss{\`{a}}, Marta R. and Cross, James and {\c{C}}elebi, Onur and Elbayad, Maha and Heafield, Kenneth and Heffernan, Kevin and Kalbassi, Elahe and Lam, Janice and Licht, Daniel and Maillard, Jean and Sun, Anna and Wang, Skyler and Wenzek, Guillaume and Youngblood, Al and Akula, Bapi and Barrault, Loic and Gonzalez, Gabriel Mejia and Hansanti, Prangthip and Hoffman, John and Jarrett, Semarley and Sadagopan, Kaushik Ram and Rowe, Dirk and Spruit, Shannon and Tran, Chau and Andrews, Pierre and Ayan, Necip Fazil and Bhosale, Shruti and Edunov, Sergey and Fan, Angela and Gao, Cynthia and Goswami, Vedanuj and Guzm{\'{a}}n, Francisco and Koehn, Philipp and Mourachko, Alexandre and Ropers, Christophe and Saleem, Safiyyah and Schwenk, Holger and Wang, Jeff},
eprint = {2207.04672},
month = {jul},
title = {{No Language Left Behind: Scaling Human-Centered Machine Translation}},
year = {2022}
}
